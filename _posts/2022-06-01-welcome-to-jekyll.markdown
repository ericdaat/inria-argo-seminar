---
layout: post
title: "Enhancing Sampling with Learning"
speaker: "Marylou Gabri√©"
speaker_url: "https://marylou-gabrie.github.io/"
speaker_institution: "CMAP, Ecole Polytechnique"
date:   2022-06-01 11:12:24 +0200
categories: jekyll update
---

In many applications in computational sciences and statistical
inference, one seeks to compute expectations on complex high-dimensional
distributions. Multi-modality poses one of the biggest challenges in these
computations; slow mixing between unconnected modes leads to slow convergence
of estimators. On the other hand, deep generative models parametrize,
with neural networks, very flexible families of distributions from which
independent samples can be obtained at negligible costs. In this talk,
I will quickly review recent works trying to enhance traditional inference
and sampling algorithms with learning. In particular, I will present a
recent work on an adaptive MCMC with normalizing flows. We will see how
blending expert knowledge and learning is sometimes the winning cocktail
to a drastic acceleration of MCMC convergence.
